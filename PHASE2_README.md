# Phase 2 Implementation Complete

## Overview

Phase 2 implements the **A2A + MCP Hybrid Architecture** with a thin orchestration layer coordinating external agents. All components are fully functional with mock implementations ready for Phase 4 enhancement with real LLMs and MCP tools.

## Architecture

```
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚                     Core Engine (Port 8000)                  â”‚
â”‚                   A2A Orchestrator + MCP Server              â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
               â”‚
               â”‚ A2A Protocol
               â”‚
       â”Œâ”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
       â”‚                â”‚            â”‚              â”‚
       â–¼                â–¼            â–¼              â–¼
â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”  â”Œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
â”‚   Planner   â”‚  â”‚Knowledge â”‚  â”‚Knowledgeâ”‚  â”‚   Data   â”‚
â”‚   Agent     â”‚  â”‚Provider  â”‚  â”‚Provider â”‚  â”‚  Agents  â”‚
â”‚  (9000)     â”‚  â”‚  SOP     â”‚  â”‚  Error  â”‚  â”‚KQL/SPL   â”‚
â”‚             â”‚  â”‚ (9010)   â”‚  â”‚ (9011)  â”‚  â”‚SQL       â”‚
â”‚             â”‚  â”‚          â”‚  â”‚         â”‚  â”‚9020-9022 â”‚
â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜  â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
```

## Components Implemented

### 1. Core Engine Service (Port 8000)
**Location**: `services/core-engine/src/`

**Key Files**:
- `orchestrator.py` - A2AOrchestrator with complete workflow logic
- `main.py` - FastAPI service with MCP server interface
- `config.py` - Configuration management

**Capabilities**:
- Agent discovery and invocation
- Workflow orchestration (9-step process)
- Journey-level cost tracking
- State machine management
- MCP server interface (Phase 2 placeholder)

**API Endpoints**:
- `POST /api/v1/query` - Process query through A2A workflow
- `GET /api/v1/journey/{id}` - Get journey context
- `GET /api/v1/journey/{id}/cost` - Get cost summary
- `POST /mcp/tools/list` - List MCP tools
- `POST /mcp/tools/call` - Execute MCP tool

### 2. Mock Planner Agent (Port 9000)
**Location**: `services/mock-agents/planner/src/`

**Capabilities**:
- Analyzes natural language queries
- Creates workflow plans with knowledge + data steps
- Detects error keywords to include error knowledge agent
- Returns estimated costs and durations

**A2A Actions**:
- `create_plan` - Generate workflow plan
- `optimize_plan` - Optimize existing plan (Phase 4)

### 3. Mock Knowledge Provider Agents

#### SOP Knowledge Agent (Port 9010)
**Location**: `services/mock-agents/knowledge/src/main.py:app_sop`

**Capabilities**:
- Retrieves relevant SOP procedures
- Keyword-based matching (Phase 2)
- Returns table/column hints for query generation
- Mock data includes authentication, performance, database SOPs

**A2A Actions**:
- `retrieve_sop_context` - Get relevant procedures
- `search_procedures` - Search by tags

#### Error Knowledge Agent (Port 9011)
**Location**: `services/mock-agents/knowledge/src/main.py:app_error`

**Capabilities**:
- Retrieves known error patterns
- Returns resolution steps and query suggestions
- Mock data includes auth errors, network errors

**A2A Actions**:
- `retrieve_error_context` - Get relevant errors

### 4. Mock Data Agents

#### KQL Data Agent (Port 9020)
**Location**: `services/mock-agents/data/src/main.py:app_kql`

**Capabilities**:
- Generates Azure Log Analytics KQL queries
- Uses SOP table hints
- Template-based generation (Phase 2)
- Returns confidence scores

#### SPL Data Agent (Port 9021)
**Location**: `services/mock-agents/data/src/main.py:app_spl`

**Capabilities**:
- Generates Splunk SPL queries
- Index and sourcetype selection
- Stats and aggregations

#### SQL Data Agent (Port 9022)
**Location**: `services/mock-agents/data/src/main.py:app_sql`

**Capabilities**:
- Generates standard SQL queries
- Time-based filtering
- GROUP BY aggregations

**A2A Actions** (all data agents):
- `generate_and_execute` - Generate (and optionally execute) query

## Data Models

### Workflow Models
**Location**: `shared/models/workflow_models.py`

- `WorkflowState` - 8-state enum (PENDING â†’ COMPLETED/FAILED)
- `StateTransition` - State change tracking
- `WorkflowError` - Error tracking with retry support
- `WorkflowStep` - Individual workflow step
- `WorkflowPlan` - Complete execution plan from Planner

### A2A Protocol Models
**Location**: `shared/models/a2a_models.py`

- `A2AAgentDescriptor` - Agent discovery/registration
- `A2ATaskRequest` - Task invocation request
- `A2ATaskResponse` - Task response with cost info
- `KnowledgeContext` - Knowledge from provider agents
- `QueryResult` - Query generation/execution result
- `MCPToolCall` - MCP tool invocation tracking

### Journey Models
**Location**: `shared/models/journey_models.py`

- `JourneyContext` - Complete journey state with:
  - State history
  - Cost aggregation
  - Agent results
  - Error tracking
  - Helper methods for state management

### Cost Models
**Location**: `shared/models/cost_models.py`

- `AgentCostInfo` - Per-agent cost breakdown
- `JourneyCostSummary` - Journey-level aggregation with:
  - Cost by agent
  - Cost by service type
  - LLM/MCP call counts
  - Token usage

## Running Phase 2

### Local Development (Recommended)

Phase 2 uses a **single root-level virtual environment** for easy VS Code integration and development.

**1. Setup Development Environment**:
```powershell
# Run the setup script to create .venv at root and install all dependencies
.\scripts\setup_envs.ps1

# This will:
# - Create .venv/ at project root
# - Install shared dependencies
# - Install all service dependencies
# - Build wheel distributions (optional)
```

**2. Start All Services (Easy Mode)**:
```powershell
# Start all 7 services at once in separate windows
.\scripts\run_services.ps1

# Check service status
.\scripts\run_services.ps1 -Status

# Stop all services
.\scripts\run_services.ps1 -Stop
```

**3. Start Services Manually (Individual Control)**:
```powershell
# Activate virtual environment
.\.venv\Scripts\Activate.ps1

# Start services using Python module syntax
python -m uvicorn services.core_engine.src.main:app --port 8000 --reload
python -m uvicorn services.mock_agents.planner.src.main:app --port 9000 --reload
python -m uvicorn services.mock_agents.knowledge.src.main:app_sop --port 9010 --reload
python -m uvicorn services.mock_agents.knowledge.src.main:app_error --port 9011 --reload
python -m uvicorn services.mock_agents.data.src.main:app_kql --port 9020 --reload
python -m uvicorn services.mock_agents.data.src.main:app_spl --port 9021 --reload
python -m uvicorn services.mock_agents.data.src.main:app_sql --port 9022 --reload
```

**4. VS Code Integration**:
```powershell
# VS Code will automatically detect .venv at root
# Select interpreter: Ctrl+Shift+P -> "Python: Select Interpreter"
# Choose: .\.venv\Scripts\python.exe

# All services share the same environment - no conflicts!
```

### Docker Compose (Recommended)

**1. Build All Services**:
```powershell
docker-compose build
```

**2. Start All Services**:
```powershell
docker-compose up -d
```

**3. View Logs**:
```powershell
docker-compose logs -f core-engine
```

**4. Stop All Services**:
```powershell
docker-compose down
```

## Testing Phase 2

### Manual API Testing

**Test Query Processing**:
```powershell
curl -X POST http://localhost:8000/api/v1/query `
  -H "Content-Type: application/json" `
  -d '{
    "natural_language": "Show failed login attempts in the last hour",
    "platform": "kql",
    "user_id": "test_user"
  }'
```

**Expected Response**:
```json
{
  "journey_id": "uuid",
  "workflow_plan": {
    "plan_id": "plan_uuid",
    "steps": [...],
    "estimated_cost_usd": 0.01
  },
  "knowledge_context": {
    "sop": {...}
  },
  "queries": {
    "kql": "SigninLogs\n| where TimeGenerated > ago(1h)\n..."
  },
  "query_results": {
    "kql": {
      "platform": "kql",
      "query": "...",
      "confidence": 0.78
    }
  },
  "overall_confidence": 0.78,
  "cost_summary": {
    "total_cost_usd": 0.016,
    "cost_by_agent": {
      "mock_workflow_planner": 0.002,
      "mock_sop_knowledge": 0.003,
      "mock_kql_data": 0.006
    }
  }
}
```

### Automated Tests

**Run Integration Tests**:
```powershell
cd services/core-engine
pytest tests/test_integration.py -v
```

**Test Coverage**:
- Journey initialization
- Agent discovery
- Planner invocation
- Knowledge agent invocation
- Data agent invocation
- Complete workflow orchestration
- State machine transitions
- Cost aggregation
- Multi-platform support

## Workflow Execution

### Complete Journey Flow

1. **PENDING** â†’ User submits query
2. **DISCOVERING** â†’ Orchestrator discovers A2A agents
3. **PLANNING** â†’ Planner agent creates workflow plan
4. **GATHERING_KNOWLEDGE** â†’ Knowledge agents retrieve context (parallel)
5. **GENERATING_QUERIES** â†’ Data agents generate platform queries
6. **VALIDATING** â†’ Orchestrator validates results
7. **COMPLETED** â†’ Return comprehensive response

### Cost Tracking

**Per-Agent Granularity**:
- LLM calls and token usage
- MCP calls (ChromaDB, Azure LA, Splunk, etc.)
- Embedding operations
- Execution time

**Journey-Level Aggregation**:
- Total cost across all agents
- Cost breakdown by agent
- Cost breakdown by service type (planner/knowledge/data)

## Phase 2 vs Phase 4

### Phase 2 (Current - Mock Mode)
- âœ… Template-based query generation
- âœ… Keyword matching for knowledge retrieval
- âœ… Hardcoded agent endpoints
- âœ… No actual query execution
- âœ… No real LLM usage
- âœ… No MCP tool servers

### Phase 4 (Future - Production)
- ðŸ”„ Ollama LLM for intelligent generation
- ðŸ”„ ChromaDB + embeddings for semantic search
- ðŸ”„ GraphRAG for schema understanding
- ðŸ”„ A2A SDK for dynamic agent discovery
- ðŸ”„ Real MCP servers (ChromaDB, Azure LA, Splunk)
- ðŸ”„ Actual query execution
- ðŸ”„ Learning from successful queries

## Directory Structure

```
services/
â”œâ”€â”€ core-engine/
â”‚   â”œâ”€â”€ src/
â”‚   â”‚   â”œâ”€â”€ main.py           # FastAPI + MCP server
â”‚   â”‚   â”œâ”€â”€ orchestrator.py   # A2A orchestration logic
â”‚   â”‚   â””â”€â”€ config.py         # Configuration
â”‚   â”œâ”€â”€ tests/
â”‚   â”‚   â””â”€â”€ test_integration.py
â”‚   â”œâ”€â”€ Dockerfile
â”‚   â””â”€â”€ requirements.txt
â”œâ”€â”€ mock-agents/
â”‚   â”œâ”€â”€ planner/
â”‚   â”‚   â”œâ”€â”€ src/main.py       # Workflow planner
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â”œâ”€â”€ knowledge/
â”‚   â”‚   â”œâ”€â”€ src/main.py       # SOP + Error agents
â”‚   â”‚   â”œâ”€â”€ Dockerfile
â”‚   â”‚   â””â”€â”€ requirements.txt
â”‚   â””â”€â”€ data/
â”‚       â”œâ”€â”€ src/main.py       # KQL/SPL/SQL agents
â”‚       â”œâ”€â”€ Dockerfile
â”‚       â””â”€â”€ requirements.txt
shared/
â”œâ”€â”€ models/
â”‚   â”œâ”€â”€ workflow_models.py    # State machine
â”‚   â”œâ”€â”€ a2a_models.py         # A2A protocol
â”‚   â”œâ”€â”€ journey_models.py     # Journey tracking
â”‚   â”œâ”€â”€ cost_models.py        # Cost tracking
â”‚   â”œâ”€â”€ query_models.py       # Query request/response
â”‚   â””â”€â”€ ...
â”œâ”€â”€ interfaces/
â”‚   â””â”€â”€ ...
â””â”€â”€ utils/
    â”œâ”€â”€ logging_config.py     # Structured logging
    â””â”€â”€ exceptions.py         # Exception hierarchy
```

## Key Features Demonstrated

âœ… **A2A Protocol**: Agents communicate through standardized interface
âœ… **Cost Transparency**: Every operation tracked with journey-level aggregation
âœ… **State Machine**: Clear workflow progression with history
âœ… **Agent Discovery**: Orchestrator discovers required agents
âœ… **Knowledge Integration**: SOP and error knowledge inform query generation
âœ… **Multi-Platform**: KQL, SPL, SQL query generation
âœ… **Error Handling**: Comprehensive exception hierarchy
âœ… **Logging**: Structured JSON logs with context
âœ… **Dockerized**: All services containerized and orchestrated

## Next Steps

After Phase 2 validation:
1. Review architecture and mock behavior
2. Validate cost tracking accuracy
3. Test with various query types
4. Proceed to Phase 3: Real MCP servers
5. Proceed to Phase 4: Ollama + GraphRAG integration

## Troubleshooting

**Port Conflicts**:
```powershell
# Check ports in use
netstat -ano | findstr "8000 9000 9010 9011 9020 9021 9022"
```

**Service Not Starting**:
```powershell
# Check logs
docker-compose logs [service-name]
```

**Import Errors**:
```powershell
# Ensure PYTHONPATH includes project root
$env:PYTHONPATH="J:\projects\engine-core"
```

## Contact

For questions or issues with Phase 2 implementation, refer to:
- Architecture: `docs/PHASE2_IMPLEMENTATION_PLAN.md`
- Copilot Instructions: `.github/copilot-instructions.md`
